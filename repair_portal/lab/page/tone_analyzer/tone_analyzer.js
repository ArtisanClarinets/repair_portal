/**
 * @file Client-side controller for the Tone & Intonation Analyzer DocType.
 * @version 4.0
 * @author Artisan Clarinets AI Division
 * @copyright 2025
 * @license MIT
 *
 * @description
 * This script provides a production-grade, real-time audio analysis interface
 * within the Frappe framework.
 *
 * Key Features:
 * - Real-time pitch detection and intonation visualization.
 * - Performance-oriented design using the Web Audio API's AudioWorklet.
 * - Dynamic, smoothly animated UI rendered on an HTML5 Canvas.
 * - Robust state management and error handling.
 * - Modular class-based architecture for maintainability.
 *
 * Tech Stack:
 * - Frappe Framework (for UI integration and server communication)
 * - Web Audio API (AudioWorklet for non-blocking audio processing)
 * - HTML5 Canvas (for custom UI rendering)
 * - Frappe Charts (for harmonic analysis display)
 *
 * @requires A running Frappe instance with the associated Python backend.
 * @requires The 'tone-processor.js' AudioWorklet file in the public assets.
 */


// biome-ignore lint/suspicious/noRedundantUseStrict: # Autogenerated by Frappe
'use strict';
frappe.pages.tone_analyzer = {
	on_page_load(wrapper) {
		const page = frappe.ui.make_app_page({
			parent: wrapper,
			title: 'Tone Analyzer',
			single_column: true
		});
		page.set_primary_action(__('Start Analysis'), () => {
			page.start_analysis();
		});
	}
};

/**
 * @file Client-side controller for the Tone & Intonation Analyzer DocType.
 * @version 4.0
 * @author Artisan Clarinets AI Division
 * @copyright 2025
 * @license MIT
 *
 * @description
 * This script provides a production-grade, real-time audio analysis interface
 * within the Frappe framework.
 *
 * Key Features:
 * - Real-time pitch detection and intonation visualization.
 * - Performance-oriented design using the Web Audio API's AudioWorklet.
 * - Dynamic, smoothly animated UI rendered on an HTML5 Canvas.
 *
 * - Robust state management and error handling.
 * - Modular class-based architecture for maintainability.
 *
 * Tech Stack:
 * - Frappe Framework (for UI integration and server communication)
 * - Web Audio API (AudioWorklet for non-blocking audio processing)
 * - HTML5 Canvas (for custom UI rendering)
 * - Frappe Charts (for harmonic analysis display)
 *
 * @requires A running Frappe instance with the associated Python backend.
 * @requires The 'tone-processor.js' AudioWorklet file in the public assets.
 */

	frappe.get_doc("Tone & Intonation Analyzer").ToneAnalyzer = {
		/**
		 * Initializes the analyzer controller when the form loads.
		 * @param {object} frm - The Frappe form object.
		 */
		onload(frm) {
			frm.analyzer = new ToneAnalyzer(frm);
			frm.analyzer.initializeUI();
		},

	/**
	 * Updates the UI elements when the form is refreshed.
	 * @param {object} frm - The Frappe form object.
	 */
	refresh(frm) {
		frm.analyzer.renderControls();
		frm.analyzer.drawHarmonicsChart();
	},

	/**
	 * Cleans up resources when the form is closed.
	 * @param {object} frm - The Frappe form object.
	 */
	on_close(frm) {
		if (frm.analyzer) {
			frm.analyzer.stop();
		}
	}
};


class ToneAnalyzer {
	/**
	 * Constructs the ToneAnalyzer instance.
	 * @param {object} frm - The Frappe form object.
	 */
	constructor(frm) {
		this.frm = frm;
		this.state = {
			isRunning: false,
			audioContext: null,
			workletNode: null,
			micStream: null,
			animationFrameId: null,
			cents: 0,
			noteName: '--',
			inTuneCounter: 0,
			inTuneThreshold: 15, // frames
			pitchTolerance: 5 // cents
		};

		// DOM element references are cached for performance.
		this.elements = {};
	}

	/**
	 * Prepares the DOM by injecting necessary HTML and caching element references.
	 */
	initializeUI() {
		const customHTMLWrapper = this.frm.fields_dict.custom_html.wrapper;
		const harmonicsHTMLWrapper = this.frm.fields_dict.harmonics_html.wrapper;

		// Inject HTML structure. Note that the main containers are now in the DocType's 'Custom HTML' field.
		$(harmonicsHTMLWrapper).html('<div id="harmonics-chart" class="mt-4" style="height: 250px;"></div>');

		// Cache DOM elements
		this.elements = {
			tunerArea: $(customHTMLWrapper).find('#tuner-display-area'),
			canvas: $(customHTMLWrapper).find('#tuner-canvas').get(0),
			noteDisplay: $(customHTMLWrapper).find('#note-display'),
			inTuneIndicator: $(customHTMLWrapper).find('#in-tune-indicator'),
			harmonicsChart: $(harmonicsHTMLWrapper).find('#harmonics-chart').get(0)
		};

		this.elements.canvasContext = this.elements.canvas.getContext('2d');
	}

	/**
	 * Renders the primary user controls (e.g., Start/Stop button).
	 */
	renderControls() {
		this.frm.page.clear_custom_buttons();
		this.frm.add_custom_button(
			this.state.isRunning ? "â–  Stop Live Analysis" : "â–¶ Analyze Live Tone",
			() => this.toggleAnalysis(),
			this.state.isRunning ? "btn-danger" : "btn-primary"
		);
	}

	/**
	 * Toggles the running state of the live analysis.
	 */
	toggleAnalysis() {
		this.state.isRunning ? this.stop() : this.start();
	}

	/**
	 * Starts the audio capture and analysis process.
	 * @returns {Promise<void>}
	 */
	async start() {
		if (this.state.isRunning) return;

		try {
			// --- 1. Set up Audio Context and Worklet ---
			this.state.audioContext = new AudioContext({ sampleRate: 44100 });
			const workletPath = frappe.get_asset_path('js/tone-processor.js');
			await this.state.audioContext.audioWorklet.addModule(workletPath);

			// --- 2. Get Microphone Access ---
			this.state.micStream = await navigator.mediaDevices.getUserMedia({
				audio: { echoCancellation: false, noiseSuppression: false, autoGainControl: false }
			});

			// --- 3. Create Audio Graph ---
			const micSource = this.state.audioContext.createMediaStreamSource(this.state.micStream);
			this.state.workletNode = new AudioWorkletNode(this.state.audioContext, 'tone-processor');

			// --- 4. Set up Communication and Connect Graph ---
			this.state.workletNode.port.onmessage = this.handleProcessorMessage.bind(this);
			micSource.connect(this.state.workletNode);
			// The worklet does not need to connect to the destination, as we only need its data.

			// --- 5. Update State and UI ---
			this.state.isRunning = true;
			this.elements.tunerArea.show();
			this.renderControls();
			this.animationLoop();

		} catch (error) {
			frappe.log_error("Failed to start audio analysis:", error);
			let message = "Could not start audio analysis. Please ensure your browser supports the Web Audio API and grant microphone permissions.";
			if (error.name === "NotAllowedError") {
				message = "Microphone access was denied. Please allow access in your browser settings.";
			} else if (error.name === "NotFoundError") {
				message = "No microphone was found. Please connect a microphone and try again.";
			}
			frappe.throw({ title: "Audio Error", message: message });
			this.stop(); // Ensure cleanup on failure
		}
	}

	/**
	 * Stops the audio analysis and cleans up all resources.
	 */
	stop() {
		if (this.state.micStream) {
			this.state.micStream.getTracks().forEach(track => track.stop());
		}
		if (this.state.audioContext && this.state.audioContext.state !== 'closed') {
			this.state.audioContext.close();
		}
		if (this.state.animationFrameId) {
			cancelAnimationFrame(this.state.animationFrameId);
		}

		// Reset state
		this.state = { ...this.state, isRunning: false, audioContext: null, micStream: null, animationFrameId: null };

		this.elements.tunerArea.hide();
		this.renderControls();
	}

	/**
	 * Handles messages received from the AudioWorkletProcessor.
	 * @param {MessageEvent} event - The message event containing the audio data.
	 */
	handleProcessorMessage(event) {
		if (!this.state.isRunning) return;

		frappe.call({
			method: "repair_portal.lab.doctype.tone_intonation_analyzer.tone_intonation_analyzer.run_live_analysis",
			args: {
				chunk: Array.from(event.data), // event.data is the Float32Array from the processor
				a_ref: parseInt(this.frm.doc.reference_pitch.split("=")[1]) || 440
			},
			callback: (r) => {
				if (r.message && this.state.isRunning) {
					this.state.cents = r.message.cents_dev || 0;
					this.state.noteName = r.message.note_name || '--';
				}
			}
		});
	}

	/**
	 * The main UI rendering loop, driven by requestAnimationFrame.
	 */
	animationLoop() {
		if (!this.state.isRunning) return;

		this.updateDisplays();
		this.drawGauge();

		this.state.animationFrameId = requestAnimationFrame(this.animationLoop.bind(this));
	}

	/**
	 * Updates non-canvas text displays.
	 */
	updateDisplays() {
		this.elements.noteDisplay.text(this.state.noteName);

		const isNoteDetected = this.state.noteName !== '--';
		const isInTune = Math.abs(this.state.cents) < this.state.pitchTolerance;

		if (isNoteDetected && isInTune) {
			this.state.inTuneCounter++;
		} else {
			this.state.inTuneCounter = 0;
		}

		// Display the "in-tune" indicator after a sustained period.
		this.elements.inTuneIndicator.text(this.state.inTuneCounter > this.state.inTuneThreshold ? 'ðŸ˜Š' : '');
	}

	/**
	 * Draws the entire cent-meter gauge on the canvas.
	 */
	drawGauge() {
		const ctx = this.elements.canvasContext;
		const { width, height } = this.elements.canvas;
		ctx.clearRect(0, 0, width, height);

		const centerX = width / 2;
		const centerY = height * 0.9;
		const radius = width * 0.4;

		this.drawGaugeArc(ctx, centerX, centerY, radius);
		this.drawGaugeNeedle(ctx, centerX, centerY, radius);
	}

	/**
	 * Draws the background arc and tick marks of the gauge.
	 */
	drawGaugeArc(ctx, cx, cy, r) {
		ctx.save();

		// Draw main arc
		ctx.beginPath();
		ctx.arc(cx, cy, r, Math.PI, 2 * Math.PI);
		ctx.strokeStyle = '#6c757d';
		ctx.lineWidth = 2;
		ctx.stroke();

		// Draw green "in-tune" zone
		const zoneAngle = (this.state.pitchTolerance / 50) * (Math.PI / 2);
		ctx.beginPath();
		ctx.arc(cx, cy, r, Math.PI * 1.5 - zoneAngle, Math.PI * 1.5 + zoneAngle);
		ctx.strokeStyle = 'rgba(40, 167, 69, 0.5)';
		ctx.lineWidth = 6;
		ctx.stroke();

		// Draw tick marks
		ctx.lineWidth = 1;
		ctx.strokeStyle = '#333';
		for (let i = -50; i <= 50; i += 10) {
			const angle = Math.PI + ((i + 50) / 100) * Math.PI;
			const isZero = i === 0;
			const startRadius = isZero ? r - 20 : r - 15;

			ctx.beginPath();
			ctx.moveTo(cx + startRadius * Math.cos(angle), cy + startRadius * Math.sin(angle));
			ctx.lineTo(cx + r * Math.cos(angle), cy + r * Math.sin(angle));
			ctx.stroke();
		}
		ctx.restore();
	}

	/**
	 * Draws the needle indicating the current pitch deviation.
	 */
	drawGaugeNeedle(ctx, cx, cy, r) {
		ctx.save();

		const clampedCents = Math.max(-50, Math.min(50, this.state.cents));
		const angle = Math.PI + ((clampedCents + 50) / 100) * Math.PI;

		const isInTune = Math.abs(clampedCents) < this.state.pitchTolerance;
		ctx.fillStyle = isInTune ? '#28a745' : '#dc3545';

		// Translate and rotate context to draw the needle
		ctx.translate(cx, cy);
		ctx.rotate(angle);

		// Draw needle shape
		ctx.beginPath();
		ctx.moveTo(0, -5);
		ctx.lineTo(r * 0.9, 0);
		ctx.lineTo(0, 5);
		ctx.closePath();
		ctx.fill();

		ctx.restore();
	}

	/**
	 * Draws or updates the harmonic energy bar chart using Frappe Charts.
	 */
	drawHarmonicsChart() {
		if (!this.frm.doc.harmonics_json) {
			$(this.elements.harmonicsChart).hide();
			return;
		}
		$(this.elements.harmonicsChart).show();

		const values = JSON.parse(this.frm.doc.harmonics_json);
		if (!values || !values.length) return;

		const data = {
			labels: Array.from({ length: 10 }, (_, i) => `H${i + 1}`),
			datasets: [{ values }]
		};

		if (!this.harmonicsChartInstance) {
			this.harmonicsChartInstance = new frappe.Chart(this.elements.harmonicsChart, {
				title: "Relative Harmonic Energy",
				data: data,
				type: 'bar',
				height: 250,
				colors: ['#0d6efd'],
				tooltipOptions: { formatTooltipY: d => d ? `${d.toFixed(4)} RMS Energy` : "" }
			});
		} else {
			this.harmonicsChartInstance.update(data);
		}
	}
}